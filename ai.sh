# Remote Allama host
# export OLLAMA_HOST=http://10.8.1.11:31434


# How to run Aider with Ollama
# export OLLAMA_API_BASE=http://127.0.0.1:11434
# Start your ollama server, increasing the context window to 8k tokens
# OLLAMA_CONTEXT_LENGTH=8192 ollama serve
# aider --model ollama_chat/qwen3:14b
# aider --model ollama_chat/qwen2.5-coder:14b

